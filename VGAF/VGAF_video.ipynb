{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom tqdm import tqdm\nimport torch\nimport cv2\nimport numpy as np\nfrom PIL import Image\nfrom torchvision import transforms\nimport csv\nfrom time import time","metadata":{"execution":{"iopub.status.busy":"2022-08-29T07:05:16.044645Z","iopub.execute_input":"2022-08-29T07:05:16.045364Z","iopub.status.idle":"2022-08-29T07:05:16.052009Z","shell.execute_reply.started":"2022-08-29T07:05:16.045310Z","shell.execute_reply":"2022-08-29T07:05:16.050966Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### Get frames","metadata":{}},{"cell_type":"code","source":"data_dir = r\"D:\\VGAF_dataset\"\nprint(data_dir)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_dir(dirname):\n    resdir = data_dir + \"/\" + dirname + '_frames'\n    d = os.path.normpath(os.path.join(data_dir, dirname))\n    for filename in tqdm(os.listdir(d)):\n        '''if filename.lower().endswith('ini'):\n            continue'''\n        if os.path.isdir(os.path.normpath(os.path.join(d,filename))):\n            videofile=None\n            for fn in os.listdir(os.path.normpath(os.path.join(d,filename))):\n                '''if fn.lower().endswith('ini'):\n                    continue'''\n                videofile=fn\n            if videofile is None:\n                continue\n            filename=os.path.normpath(os.path.join(filename,videofile))\n        fn, ext = os.path.splitext(os.path.basename(filename))\n        outdir=os.path.normpath(os.path.join(resdir, fn))\n        if not os.path.exists(outdir):\n            os.makedirs(outdir)\n        command = \"ffmpeg -r 1 -i \"+os.path.join(d,filename) + \" -r 1 \"+outdir+\"/%05d.png\"\n        command = os.path.normpath(command)\n        # print(command)\n        os.system(command=command)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"process_dir('Train')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"process_dir('Val')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Detect faces in frames","metadata":{}},{"cell_type":"code","source":"print(f\"Torch: {torch.__version__}\")\n# device = 'cuda:0'\ndevice = 'cpu'\nuse_cuda = torch.cuda.is_available()\nprint(use_cuda)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from facenet_pytorch import MTCNN # pretrained model for image recognition\nmtcnn = MTCNN(keep_all=True, min_face_size=40, device=device)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from facial_analysis import FacialImageProcessing\nimgProcessing=FacialImageProcessing(False,minsize=64)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scale=1\ndef save_faces(source_path,save_path):\n    if not os.path.exists(save_path):\n        os.mkdir(os.path.normpath(save_path))\n    for folder in tqdm(os.listdir(source_path)):\n        if not os.path.exists(os.path.join(save_path, folder)):\n            os.mkdir(os.path.normpath(os.path.join(save_path, folder)))\n    \n        for image in os.listdir(os.path.join(source_path, folder)):\n            filename = os.path.join(source_path, folder, image)\n            # print(filename)\n            frame_bgr = cv2.imread(filename)\n            frame = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n            #frame=cv2.resize(frame, (0,0), fx=1/scale, fy=1/scale) \n            bounding_boxes, _ = imgProcessing.detect_faces(frame)\n\n            if len(bounding_boxes)!=0:\n                root,ext=os.path.splitext(image)\n                faces_folder=os.path.join(save_path, folder, root) \n                if not os.path.exists(faces_folder):\n                    os.mkdir(faces_folder)\n                for i,bounding_box in enumerate(bounding_boxes):\n                    outfile=os.path.join(faces_folder, str(i)+ext)\n                    if not os.path.exists(outfile):\n                        bounding_box*=scale\n                        b=[max(0,int(bi)) for bi in bounding_box]\n                        x1,y1,x2,y2=b[0:4]\n                        face_img=frame_bgr[y1:y2,x1:x2,:]\n\n                        if np.prod(face_img.shape)==0:\n                            print('Empty face ',b,' found for ',filename)\n                            continue\n                        #face_img=cv2.resize(face_img,INPUT_SIZE)\n                        cv2.imwrite(outfile, face_img) \n        \n        \nsave_faces(os.path.join(data_dir,'Val_frames'),os.path.join(data_dir,'Val_faces'))\nsave_faces(os.path.join(data_dir,'Train_frames'),os.path.join(data_dir,'Train_faces'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Extract features from frames","metadata":{}},{"cell_type":"code","source":"data_dir = r\"../input/vgaf-dataset\"","metadata":{"execution":{"iopub.status.busy":"2022-08-29T07:05:26.301373Z","iopub.execute_input":"2022-08-29T07:05:26.302078Z","iopub.status.idle":"2022-08-29T07:05:26.306944Z","shell.execute_reply.started":"2022-08-29T07:05:26.302040Z","shell.execute_reply":"2022-08-29T07:05:26.305852Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"idx_to_class = {1: 'Positive', 2: 'Neutral', 3: 'Negative'}","metadata":{"execution":{"iopub.status.busy":"2022-08-29T07:05:27.690389Z","iopub.execute_input":"2022-08-29T07:05:27.690807Z","iopub.status.idle":"2022-08-29T07:05:27.696078Z","shell.execute_reply.started":"2022-08-29T07:05:27.690773Z","shell.execute_reply":"2022-08-29T07:05:27.694781Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"!pip install timm==0.4.5","metadata":{"execution":{"iopub.status.busy":"2022-08-29T07:05:29.390305Z","iopub.execute_input":"2022-08-29T07:05:29.390706Z","iopub.status.idle":"2022-08-29T07:05:43.809637Z","shell.execute_reply.started":"2022-08-29T07:05:29.390673Z","shell.execute_reply":"2022-08-29T07:05:43.808426Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Collecting timm==0.4.5\n  Downloading timm-0.4.5-py3-none-any.whl (287 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.4/287.4 kB\u001b[0m \u001b[31m874.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from timm==0.4.5) (0.12.0)\nRequirement already satisfied: torch>=1.4 in /opt/conda/lib/python3.7/site-packages (from timm==0.4.5) (1.11.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch>=1.4->timm==0.4.5) (4.3.0)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision->timm==0.4.5) (2.28.1)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.7/site-packages (from torchvision->timm==0.4.5) (9.1.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torchvision->timm==0.4.5) (1.21.6)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->timm==0.4.5) (2.1.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->timm==0.4.5) (1.26.12)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->timm==0.4.5) (2022.6.15)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->timm==0.4.5) (3.3)\nInstalling collected packages: timm\nSuccessfully installed timm-0.4.5\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"IMG_SIZE=224\nPATH='../input/enet-b2/enet_b2_8.pt'\ntest_transforms = transforms.Compose(\n    [\n        transforms.Resize((IMG_SIZE,IMG_SIZE)),\n        #transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n    ]\n)\nnp_transforms = transforms.Compose(\n    [\n        transforms.ToPILImage(None),\n        transforms.Resize((IMG_SIZE,IMG_SIZE)),\n        #transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                     std=[0.229, 0.224, 0.225])\n    ]\n)\n\nfeature_extractor_model = torch.load(PATH)","metadata":{"execution":{"iopub.status.busy":"2022-08-29T07:05:43.812497Z","iopub.execute_input":"2022-08-29T07:05:43.812987Z","iopub.status.idle":"2022-08-29T07:05:47.841022Z","shell.execute_reply.started":"2022-08-29T07:05:43.812936Z","shell.execute_reply":"2022-08-29T07:05:47.839790Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"classifier_weights=feature_extractor_model.classifier.weight.cpu().data.numpy()\nclassifier_bias=feature_extractor_model.classifier.bias.cpu().data.numpy()\nprint(classifier_weights.shape,classifier_weights)\nprint(classifier_bias.shape,classifier_bias)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = 'cuda:0'\nfeature_extractor_model.classifier=torch.nn.Identity()\nfeature_extractor_model.to(device)\nfeature_extractor_model.eval()","metadata":{"execution":{"iopub.status.busy":"2022-08-29T07:05:47.842391Z","iopub.execute_input":"2022-08-29T07:05:47.842783Z","iopub.status.idle":"2022-08-29T07:05:47.869068Z","shell.execute_reply.started":"2022-08-29T07:05:47.842747Z","shell.execute_reply":"2022-08-29T07:05:47.868113Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"EfficientNet(\n  (conv_stem): Conv2dSame(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n  (bn1): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (act1): SiLU(inplace=True)\n  (blocks): Sequential(\n    (0): Sequential(\n      (0): DepthwiseSeparableConv(\n        (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n        (bn1): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): SiLU(inplace=True)\n        (se): SqueezeExcite(\n          (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n          (act1): SiLU(inplace=True)\n          (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn2): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): Identity()\n      )\n      (1): DepthwiseSeparableConv(\n        (conv_dw): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n        (bn1): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): SiLU(inplace=True)\n        (se): SqueezeExcite(\n          (conv_reduce): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1))\n          (act1): SiLU(inplace=True)\n          (conv_expand): Conv2d(4, 16, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (conv_pw): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn2): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): Identity()\n      )\n    )\n    (1): Sequential(\n      (0): InvertedResidual(\n        (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): SiLU(inplace=True)\n        (conv_dw): Conv2dSame(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n        (bn2): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): SiLU(inplace=True)\n        (se): SqueezeExcite(\n          (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n          (act1): SiLU(inplace=True)\n          (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): InvertedResidual(\n        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): SiLU(inplace=True)\n        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n        (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): SiLU(inplace=True)\n        (se): SqueezeExcite(\n          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n          (act1): SiLU(inplace=True)\n          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): InvertedResidual(\n        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): SiLU(inplace=True)\n        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n        (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): SiLU(inplace=True)\n        (se): SqueezeExcite(\n          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n          (act1): SiLU(inplace=True)\n          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (2): Sequential(\n      (0): InvertedResidual(\n        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): SiLU(inplace=True)\n        (conv_dw): Conv2dSame(144, 144, kernel_size=(5, 5), stride=(2, 2), groups=144, bias=False)\n        (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): SiLU(inplace=True)\n        (se): SqueezeExcite(\n          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n          (act1): SiLU(inplace=True)\n          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (conv_pwl): Conv2d(144, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): InvertedResidual(\n        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): SiLU(inplace=True)\n        (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n        (bn2): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): SiLU(inplace=True)\n        (se): SqueezeExcite(\n          (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n          (act1): SiLU(inplace=True)\n          (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): InvertedResidual(\n        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): SiLU(inplace=True)\n        (conv_dw): Conv2d(288, 288, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=288, bias=False)\n        (bn2): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): SiLU(inplace=True)\n        (se): SqueezeExcite(\n          (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n          (act1): SiLU(inplace=True)\n          (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (conv_pwl): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (3): Sequential(\n      (0): InvertedResidual(\n        (conv_pw): Conv2d(48, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): SiLU(inplace=True)\n        (conv_dw): Conv2dSame(288, 288, kernel_size=(3, 3), stride=(2, 2), groups=288, bias=False)\n        (bn2): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): SiLU(inplace=True)\n        (se): SqueezeExcite(\n          (conv_reduce): Conv2d(288, 12, kernel_size=(1, 1), stride=(1, 1))\n          (act1): SiLU(inplace=True)\n          (conv_expand): Conv2d(12, 288, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (conv_pwl): Conv2d(288, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): InvertedResidual(\n        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): SiLU(inplace=True)\n        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n        (bn2): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): SiLU(inplace=True)\n        (se): SqueezeExcite(\n          (conv_reduce): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n          (act1): SiLU(inplace=True)\n          (conv_expand): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): InvertedResidual(\n        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): SiLU(inplace=True)\n        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n        (bn2): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): SiLU(inplace=True)\n        (se): SqueezeExcite(\n          (conv_reduce): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n          (act1): SiLU(inplace=True)\n          (conv_expand): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (3): InvertedResidual(\n        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): SiLU(inplace=True)\n        (conv_dw): Conv2d(528, 528, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=528, bias=False)\n        (bn2): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): SiLU(inplace=True)\n        (se): SqueezeExcite(\n          (conv_reduce): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n          (act1): SiLU(inplace=True)\n          (conv_expand): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (conv_pwl): Conv2d(528, 88, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(88, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (4): Sequential(\n      (0): InvertedResidual(\n        (conv_pw): Conv2d(88, 528, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): SiLU(inplace=True)\n        (conv_dw): Conv2d(528, 528, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=528, bias=False)\n        (bn2): BatchNorm2d(528, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): SiLU(inplace=True)\n        (se): SqueezeExcite(\n          (conv_reduce): Conv2d(528, 22, kernel_size=(1, 1), stride=(1, 1))\n          (act1): SiLU(inplace=True)\n          (conv_expand): Conv2d(22, 528, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (conv_pwl): Conv2d(528, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(120, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): InvertedResidual(\n        (conv_pw): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(720, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): SiLU(inplace=True)\n        (conv_dw): Conv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n        (bn2): BatchNorm2d(720, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): SiLU(inplace=True)\n        (se): SqueezeExcite(\n          (conv_reduce): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n          (act1): SiLU(inplace=True)\n          (conv_expand): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (conv_pwl): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(120, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): InvertedResidual(\n        (conv_pw): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(720, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): SiLU(inplace=True)\n        (conv_dw): Conv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n        (bn2): BatchNorm2d(720, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): SiLU(inplace=True)\n        (se): SqueezeExcite(\n          (conv_reduce): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n          (act1): SiLU(inplace=True)\n          (conv_expand): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (conv_pwl): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(120, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (3): InvertedResidual(\n        (conv_pw): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(720, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): SiLU(inplace=True)\n        (conv_dw): Conv2d(720, 720, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=720, bias=False)\n        (bn2): BatchNorm2d(720, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): SiLU(inplace=True)\n        (se): SqueezeExcite(\n          (conv_reduce): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n          (act1): SiLU(inplace=True)\n          (conv_expand): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (conv_pwl): Conv2d(720, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(120, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (5): Sequential(\n      (0): InvertedResidual(\n        (conv_pw): Conv2d(120, 720, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(720, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): SiLU(inplace=True)\n        (conv_dw): Conv2dSame(720, 720, kernel_size=(5, 5), stride=(2, 2), groups=720, bias=False)\n        (bn2): BatchNorm2d(720, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): SiLU(inplace=True)\n        (se): SqueezeExcite(\n          (conv_reduce): Conv2d(720, 30, kernel_size=(1, 1), stride=(1, 1))\n          (act1): SiLU(inplace=True)\n          (conv_expand): Conv2d(30, 720, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (conv_pwl): Conv2d(720, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): InvertedResidual(\n        (conv_pw): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): SiLU(inplace=True)\n        (conv_dw): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n        (bn2): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): SiLU(inplace=True)\n        (se): SqueezeExcite(\n          (conv_reduce): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n          (act1): SiLU(inplace=True)\n          (conv_expand): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (conv_pwl): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (2): InvertedResidual(\n        (conv_pw): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): SiLU(inplace=True)\n        (conv_dw): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n        (bn2): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): SiLU(inplace=True)\n        (se): SqueezeExcite(\n          (conv_reduce): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n          (act1): SiLU(inplace=True)\n          (conv_expand): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (conv_pwl): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (3): InvertedResidual(\n        (conv_pw): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): SiLU(inplace=True)\n        (conv_dw): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n        (bn2): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): SiLU(inplace=True)\n        (se): SqueezeExcite(\n          (conv_reduce): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n          (act1): SiLU(inplace=True)\n          (conv_expand): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (conv_pwl): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (4): InvertedResidual(\n        (conv_pw): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): SiLU(inplace=True)\n        (conv_dw): Conv2d(1248, 1248, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1248, bias=False)\n        (bn2): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): SiLU(inplace=True)\n        (se): SqueezeExcite(\n          (conv_reduce): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n          (act1): SiLU(inplace=True)\n          (conv_expand): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (conv_pwl): Conv2d(1248, 208, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (6): Sequential(\n      (0): InvertedResidual(\n        (conv_pw): Conv2d(208, 1248, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): SiLU(inplace=True)\n        (conv_dw): Conv2d(1248, 1248, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1248, bias=False)\n        (bn2): BatchNorm2d(1248, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): SiLU(inplace=True)\n        (se): SqueezeExcite(\n          (conv_reduce): Conv2d(1248, 52, kernel_size=(1, 1), stride=(1, 1))\n          (act1): SiLU(inplace=True)\n          (conv_expand): Conv2d(52, 1248, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (conv_pwl): Conv2d(1248, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(352, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): InvertedResidual(\n        (conv_pw): Conv2d(352, 2112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn1): BatchNorm2d(2112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act1): SiLU(inplace=True)\n        (conv_dw): Conv2d(2112, 2112, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2112, bias=False)\n        (bn2): BatchNorm2d(2112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n        (act2): SiLU(inplace=True)\n        (se): SqueezeExcite(\n          (conv_reduce): Conv2d(2112, 88, kernel_size=(1, 1), stride=(1, 1))\n          (act1): SiLU(inplace=True)\n          (conv_expand): Conv2d(88, 2112, kernel_size=(1, 1), stride=(1, 1))\n        )\n        (conv_pwl): Conv2d(2112, 352, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (bn3): BatchNorm2d(352, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n  )\n  (conv_head): Conv2d(352, 1408, kernel_size=(1, 1), stride=(1, 1), bias=False)\n  (bn2): BatchNorm2d(1408, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  (act2): SiLU(inplace=True)\n  (global_pool): SelectAdaptivePool2d (pool_type=max, flatten=True)\n  (classifier): Identity()\n)"},"metadata":{}}]},{"cell_type":"code","source":"def get_features_scores(data_dir):\n    videoname2features={}\n    if 'Train_faces' in data_dir:\n        data_dir = '../input/vgaf-dataset/Train_faces/Train_faces'\n    if 'Val_faces' in data_dir:\n        data_dir = '../input/vgaf-dataset/Val_faces/Val_faces'\n    for videoname in tqdm(os.listdir(data_dir)): # 2_1\n        frames_dir=os.path.join(data_dir,videoname) \n        X_global_features = [] # features каждого кадра\n        for filename in sorted(os.listdir(frames_dir)): # 00001 - directory with faces of the frame \n            faces_dir=os.path.join(frames_dir,filename)\n            imgs=[] # тензоры лиц одного кадра\n\n            for img_name in sorted(os.listdir(faces_dir)): # лицо\n                #print(img_name)\n                \n                img = Image.open(os.path.join(faces_dir,img_name)) # открываем // по-другому считали и обработали изображение\n                img_tensor = test_transforms(img) # transform\n                # print('Image open and transform', time() - start)\n                \n                if img.size:\n                    imgs.append(img_tensor) # добавляем в imgs\n                    # print('img_tensor.shape', img_tensor.shape)\n\n            if len(imgs)>0: # если лица есть \n                # inp = preprocessing_function(np.array(imgs, dtype=np.float32))\n                stacked_images = torch.stack(imgs, dim=0).to(device)\n                features = feature_extractor_model(stacked_images) # конкатенация изображений (img.shape = 3,224,224 // torch.stack.shape = 7,3,224,224) time()\n                # print('features.shape', features.shape)\n                #print(features.is_cuda)\n                #print(videoname,filename,global_features.shape,feats.shape,scores.shape)\n                features = features.data.cpu().numpy()\n                X_global_features.append(features)\n                # print('Get features', time() - start)\n        \n        #print(videoname,len(X_global_features))\n        videoname2features[videoname] = X_global_features\n    return videoname2features\n\nvideo2Allfeatures_val=get_features_scores(os.path.join(data_dir,'Val_faces'))\n#video2Allfeatures_train=get_features_scores(os.path.join(data_dir,'Train_faces'))","metadata":{"execution":{"iopub.status.busy":"2022-08-29T07:06:29.114706Z","iopub.execute_input":"2022-08-29T07:06:29.115072Z","iopub.status.idle":"2022-08-29T08:06:57.781894Z","shell.execute_reply.started":"2022-08-29T07:06:29.115040Z","shell.execute_reply":"2022-08-29T08:06:57.780889Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"100%|██████████| 741/741 [1:00:28<00:00,  4.90s/it]\n","output_type":"stream"}]},{"cell_type":"code","source":"video2Allfeatures_train['2_1'][0].shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pickle\nmodel_name = 'enet_b2_8'\nMODEL2EMOTIW_FEATURES=model_name+'_vgaf_val.pickle' \n\nprint(MODEL2EMOTIW_FEATURES)\n","metadata":{"execution":{"iopub.status.busy":"2022-08-29T08:10:25.300854Z","iopub.execute_input":"2022-08-29T08:10:25.301214Z","iopub.status.idle":"2022-08-29T08:10:25.307709Z","shell.execute_reply.started":"2022-08-29T08:10:25.301182Z","shell.execute_reply":"2022-08-29T08:10:25.306593Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"enet_b2_8_vgaf_val.pickle\n","output_type":"stream"}]},{"cell_type":"code","source":"with open(MODEL2EMOTIW_FEATURES, 'wb') as handle:\n    pickle.dump(video2Allfeatures_val, handle, protocol=pickle.HIGHEST_PROTOCOL)\n#print(len(video2Allfeatures_train),len(video2Allfeatures_val))","metadata":{"execution":{"iopub.status.busy":"2022-08-29T08:10:32.596538Z","iopub.execute_input":"2022-08-29T08:10:32.597521Z","iopub.status.idle":"2022-08-29T08:10:39.311674Z","shell.execute_reply.started":"2022-08-29T08:10:32.597484Z","shell.execute_reply":"2022-08-29T08:10:39.310628Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"def create_dataset(videoname2features,labelsfile):\n    x = []\n    y = []\n    has_faces=[]\n    ind=0\n    with open(labelsfile, mode='r') as csvfile:\n        labels_reader = csv.reader(csvfile, delimiter=' ')\n        for i,row in enumerate(labels_reader):\n            if i==0:\n                #print('first:',row)\n                continue\n            print(row) \n            videoname,label=row[0],int(row[1]) # row[0] - 2_1 videoname, int(row[1]) - 2 label\n            print(videoname,label)\n            X_global_features=videoname2features[videoname]\n            #print(videoname,label,len(X_global_features))\n            \n            total_features=[]\n            for cur_features in X_global_features: # cur_features - фичи каждого кадра\n                #print(cur_features.shape)\n                if False:\n                    total_features.extend(cur_features)\n                else:\n                    mean_features = (np.mean(cur_features, axis=0))\n                    std_features = (np.std(cur_features, axis=0))\n                    max_features = (np.max(cur_features, axis=0))\n                    min_features = (np.min(cur_features, axis=0))\n\n                    # join several features together\n                    #feature = np.concatenate((mean_features, std_features, min_features, max_features), axis=None)                    \n                    #feature = np.concatenate((mean_features, std_features, min_features), axis=None)\n                    #feature = np.concatenate((mean_features, min_features, max_features), axis=None)\n                    feature = np.concatenate((mean_features,std_features), axis=None)\n                    #feature = np.concatenate((max_features,mean_features,std_features), axis=None)\n                    #feature=max_features\n\n                    total_features.append(feature)\n            \n            if len(total_features)>0:\n                total_features=np.array(total_features)\n                mean_features = (np.mean(total_features, axis=0))\n                std_features = (np.std(total_features, axis=0))\n                max_features = (np.max(total_features, axis=0))\n                min_features = (np.min(total_features, axis=0))\n\n                # join several features together\n                #feature = np.concatenate((mean_features, std_features, min_features, max_features), axis=None)                    \n                #feature = np.concatenate((mean_features, std_features, min_features), axis=None)\n                feature = np.concatenate((mean_features,std_features), axis=None)\n                #feature = np.concatenate((max_features,std_features), axis=None)\n                #feature=std_features\n                x.append(feature)\n                has_faces.append(1)\n            else:\n                x.append(np.zeros_like(feature))\n                has_faces.append(0)\n            y.append(label-1)\n    x=np.array(x)\n    y=np.array(y)\n    has_faces=np.array(has_faces)\n    print(x.shape,y.shape)\n    return x,y,has_faces\n\nx_train, y_train, has_faces_train = create_dataset(video2Allfeatures_train,os.path.join(data_dir,'Train_labels.txt'))\nx_test, y_test, has_faces_test = create_dataset(video2Allfeatures_val,os.path.join(DATA_DIR,'Val_labels.txt'))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train[0].shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import svm,metrics,preprocessing\n\nx_train_norm=preprocessing.normalize(x_train_enet,norm='l2')\nx_test_norm=preprocessing.normalize(x_test_enet,norm='l2')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svc_clf = svm.LinearSVC(C=1.1) #0.5 1.1 0.6\n#clf = svm.SVC(C=10.0, gamma=1.0, kernel='rbf')\n#np.random.seed(1)\n#clf=RandomForestClassifier(n_estimators=1000,max_depth=7, n_jobs=-1)\n#clf=KNeighborsClassifier(n_neighbors=3,p=2)\n\n#import xgboost as xgb\n#clf = xgb.XGBClassifier(n_estimators=1000,use_label_encoder=False)\n\nif True:    \n    svc_clf.fit(x_train_norm[has_faces_train==1], y_train_enet[has_faces_train==1])\n    y_pred = svc_clf.predict(x_test_norm)\nelse:\n    clf.fit(x_train[has_faces_train==1], y_train[has_faces_train==1])\n    y_pred = clf.predict(x_test)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test_enet[has_faces_test==1], y_pred[has_faces_test==1]))\nprint(\"Complete accuracy:\",metrics.accuracy_score(y_test_enet, y_pred))","metadata":{},"execution_count":null,"outputs":[]}]}