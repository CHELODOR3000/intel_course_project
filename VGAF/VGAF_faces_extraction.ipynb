{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import csv\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\VGAF_dataset\n"
     ]
    }
   ],
   "source": [
    "data_dir = r\"D:\\VGAF_dataset\"\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dir(dirname):\n",
    "    resdir = data_dir + \"/\" + dirname + '_frames'\n",
    "    d = os.path.normpath(os.path.join(data_dir, dirname))\n",
    "    for filename in tqdm(os.listdir(d)):\n",
    "        '''if filename.lower().endswith('ini'):\n",
    "            continue'''\n",
    "        if os.path.isdir(os.path.normpath(os.path.join(d,filename))):\n",
    "            videofile=None\n",
    "            for fn in os.listdir(os.path.normpath(os.path.join(d,filename))):\n",
    "                '''if fn.lower().endswith('ini'):\n",
    "                    continue'''\n",
    "                videofile=fn\n",
    "            if videofile is None:\n",
    "                continue\n",
    "            filename=os.path.normpath(os.path.join(filename,videofile))\n",
    "        fn, ext = os.path.splitext(os.path.basename(filename))\n",
    "        outdir=os.path.normpath(os.path.join(resdir, fn))\n",
    "        if not os.path.exists(outdir):\n",
    "            os.makedirs(outdir)\n",
    "        command = \"ffmpeg -r 1 -i \"+os.path.join(d,filename) + \" -r 1 \"+outdir+\"/%05d.png\"\n",
    "        command = os.path.normpath(command)\n",
    "        # print(command)\n",
    "        os.system(command=command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2661/2661 [10:04:21<00:00, 13.63s/it]   \n"
     ]
    }
   ],
   "source": [
    "process_dir('Train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 766/766 [1:27:44<00:00,  6.87s/it]\n"
     ]
    }
   ],
   "source": [
    "process_dir('Val')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect faces in frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch: 1.9.1\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(f\"Torch: {torch.__version__}\")\n",
    "# device = 'cuda:0'\n",
    "device = 'cpu'\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN # pretrained model for image recognition\n",
    "mtcnn = MTCNN(keep_all=True, min_face_size=40, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facial_analysis import FacialImageProcessing\n",
    "imgProcessing=FacialImageProcessing(False,minsize=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 766/766 [4:49:47<00:00, 22.70s/it]  \n",
      "100%|██████████| 2661/2661 [19:33:10<00:00, 26.45s/it]   \n"
     ]
    }
   ],
   "source": [
    "scale=1\n",
    "def save_faces(source_path,save_path):\n",
    "    if not os.path.exists(save_path):\n",
    "        os.mkdir(os.path.normpath(save_path))\n",
    "    for folder in tqdm(os.listdir(source_path)):\n",
    "        if not os.path.exists(os.path.join(save_path, folder)):\n",
    "            os.mkdir(os.path.normpath(os.path.join(save_path, folder)))\n",
    "    \n",
    "        for image in os.listdir(os.path.join(source_path, folder)):\n",
    "            filename = os.path.join(source_path, folder, image)\n",
    "            # print(filename)\n",
    "            frame_bgr = cv2.imread(filename)\n",
    "            frame = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "            #frame=cv2.resize(frame, (0,0), fx=1/scale, fy=1/scale) \n",
    "            bounding_boxes, _ = imgProcessing.detect_faces(frame)\n",
    "\n",
    "            if len(bounding_boxes)!=0:\n",
    "                root,ext=os.path.splitext(image)\n",
    "                faces_folder=os.path.join(save_path, folder, root) \n",
    "                if not os.path.exists(faces_folder):\n",
    "                    os.mkdir(faces_folder)\n",
    "                for i,bounding_box in enumerate(bounding_boxes):\n",
    "                    outfile=os.path.join(faces_folder, str(i)+ext)\n",
    "                    if not os.path.exists(outfile):\n",
    "                        bounding_box*=scale\n",
    "                        b=[max(0,int(bi)) for bi in bounding_box]\n",
    "                        x1,y1,x2,y2=b[0:4]\n",
    "                        face_img=frame_bgr[y1:y2,x1:x2,:]\n",
    "\n",
    "                        if np.prod(face_img.shape)==0:\n",
    "                            print('Empty face ',b,' found for ',filename)\n",
    "                            continue\n",
    "                        #face_img=cv2.resize(face_img,INPUT_SIZE)\n",
    "                        cv2.imwrite(outfile, face_img) \n",
    "        \n",
    "        \n",
    "save_faces(os.path.join(data_dir,'Val_frames'),os.path.join(data_dir,'Val_faces'))\n",
    "save_faces(os.path.join(data_dir,'Train_frames'),os.path.join(data_dir,'Train_faces'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
