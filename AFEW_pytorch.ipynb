{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b364f3dd",
   "metadata": {},
   "source": [
    "## Evaluation of accuracy with EfficientNet-B0 without classifier (7 emotions - 36.59% / 5 emotions - 49.12%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b0664244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from torchvision import datasets, transforms\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "05e26c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR=r'D:\\Users\\amira\\Documents\\datasets\\emotions\\AudioVideo\\faces\\Val_AFEW'\n",
    "IMG_SIZE = 224\n",
    "\n",
    "test_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE,IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0baff978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (conv_stem): Conv2dSame(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): SiLU(inplace=True)\n",
       "  (blocks): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2dSame(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
       "        (bn2): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2dSame(144, 144, kernel_size=(5, 5), stride=(2, 2), groups=144, bias=False)\n",
       "        (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "        (bn2): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2dSame(240, 240, kernel_size=(3, 3), stride=(2, 2), groups=240, bias=False)\n",
       "        (bn2): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (bn2): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (bn2): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "        (bn2): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2dSame(672, 672, kernel_size=(5, 5), stride=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act2): SiLU(inplace=True)\n",
       "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=True)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=1280, out_features=8, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_to_idx = {'Angry': 0, 'Contempt': 1, 'Disgust': 2, 'Fear': 3, 'Happy': 4, 'Neutral': 5, 'Sad': 6, 'Surprise': 7}\n",
    "idx_to_class = {0: 'Angry', 1: 'Contempt', 2: 'Disgust', 3: 'Fear', 4: 'Happy', 5: 'Neutral', 6: 'Sad', 7: 'Surprise'}\n",
    "emotion_to_index = {'Angry':0, 'Disgust':1, 'Fear':2, 'Happy':3, 'Neutral':4, 'Sad':5, 'Surprise':6}\n",
    "\n",
    "PATH = r'D:\\Users\\amira\\openvino_notebooks\\notebooks\\accuracy_afew\\models\\enet_b0_8\\enet_b0_8'\n",
    "device = 'cuda:0'\n",
    "model = torch.load(PATH)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "60e1c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(input):\n",
    "    modified_input = np.subtract(input, input.max(axis=0, keepdims=True))\n",
    "\n",
    "    # Get unnormalized probabilities\n",
    "    exp_values = np.exp(modified_input - np.max(modified_input, axis=0, keepdims=True))\n",
    "    # Normalize them for each sample\n",
    "    probabilities = exp_values / np.sum(exp_values, axis=0, keepdims=True)\n",
    "\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5e0cba21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d03fe56e764140078cb72a29a8c1a319",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f036631f5b142bb8a9abf65b261ffb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c8567ded5d44a5b6938f06ae71a136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0f224e24a744a34a7b3ca433f79c2dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7af836bf574b49f3b4c6e71603b564e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a1466d5a1f74658a510d91ad5cd3c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed1bf3027e9b40458df9ea32d9421a71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19962, 8) (19962,)\n"
     ]
    }
   ],
   "source": [
    "y_val,y_scores_val=[],[]\n",
    "\n",
    "for class_name in os.listdir(DATA_DIR):\n",
    "    if class_name in class_to_idx:\n",
    "        class_dir=os.path.join(DATA_DIR,class_name)\n",
    "        y=class_to_idx[class_name]\n",
    "        for video_name in tqdm(os.listdir(class_dir)):\n",
    "            video_dir = os.path.join(class_dir,video_name)\n",
    "            for img_name in os.listdir(video_dir):\n",
    "                if 'noface' not in img_name:\n",
    "                    filepath=os.path.join(video_dir,img_name)\n",
    "                    img = Image.open(filepath)\n",
    "                    img_tensor = test_transforms(img)\n",
    "                    img_tensor.unsqueeze_(0)\n",
    "                    scores = model(img_tensor.to(device))\n",
    "                    scores=scores[0].data.cpu().numpy()\n",
    "                    #print(scores.shape)\n",
    "                    y_scores_val.append(softmax(scores))\n",
    "                    y_val.append(y)\n",
    "\n",
    "y_scores_val=np.array(y_scores_val)\n",
    "y_val=np.array(y_val)\n",
    "print(y_scores_val.shape,y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "94615c86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.22192165113716\n",
      "Angry 1220/3297 acc: 37.003336\n",
      "Contempt 0/0 acc: nan\n",
      "Disgust 372/2485 acc: 14.969819\n",
      "Fear 671/1703 acc: 39.401057\n",
      "Happy 1577/3320 acc: 47.500000\n",
      "Neutral 798/3693 acc: 21.608448\n",
      "Sad 1910/3356 acc: 56.912992\n",
      "Surprise 483/2108 acc: 22.912713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\amira\\AppData\\Local\\Temp\\ipykernel_1104\\1864895788.py:8: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  _val_acc=(y_pred[y_val==i]==i).sum()/(y_val==i).sum()\n"
     ]
    }
   ],
   "source": [
    "y_pred=np.argmax(y_scores_val,axis=1)\n",
    "acc=100.0*(y_val==y_pred).sum()/len(y_val)\n",
    "print(acc)\n",
    "\n",
    "y_train=np.array(y_val)\n",
    "\n",
    "for i in range(y_scores_val.shape[1]):\n",
    "    _val_acc=(y_pred[y_val==i]==i).sum()/(y_val==i).sum()\n",
    "    print('%s %d/%d acc: %f' %(idx_to_class[i],(y_pred[y_val==i]==i).sum(),(y_val==i).sum(),100*_val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f4f3587e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19962, 7)\n",
      "36.59452960625188\n"
     ]
    }
   ],
   "source": [
    "# Model was trained on 8 emotions on AffectNet so we have to delete 1 emotion that is not on AFEW\n",
    "сontempt_idx=class_to_idx['Contempt']\n",
    "y_scores_val_filtered=y_scores_val[:, [i!=сontempt_idx for i in idx_to_class]]\n",
    "print(y_scores_val_filtered.shape)\n",
    "y_pred=np.argmax(y_scores_val_filtered,axis=1)\n",
    "other_indices=y_val!=сontempt_idx\n",
    "y_val_new=np.array([y if y<сontempt_idx else y-1 for y in y_val if y!=сontempt_idx])\n",
    "acc=100.0*np.mean(y_val_new==y_pred[other_indices])\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5b58fb",
   "metadata": {},
   "source": [
    "5 emotions that [model](https://github.com/openvinotoolkit/open_model_zoo/tree/master/models/intel/emotions-recognition-retail-0003) from OpenVino's OMZ can classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b617425a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19962, 5)\n",
      "49.125142639786986\n"
     ]
    }
   ],
   "source": [
    "irrelevant_idxs = [class_to_idx['Contempt'], class_to_idx['Disgust'], class_to_idx['Fear']]\n",
    "\n",
    "y_scores_val_filtered=y_scores_val[:, [i not in irrelevant_idxs for i in idx_to_class]]\n",
    "print(y_scores_val_filtered.shape)\n",
    "\n",
    "y_pred=np.argmax(y_scores_val_filtered,axis=1)\n",
    "other_indices=[i not in irrelevant_idxs for i in y_val]\n",
    "y_val_new=np.array([y if y<class_to_idx['Contempt'] else y-3 for y in y_val if y not in irrelevant_idxs])\n",
    "acc=100.0*np.mean(y_val_new==y_pred[other_indices])\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cd19a6",
   "metadata": {},
   "source": [
    "## Evaluation of accuracy with EfficientNet-B0 with classifier - 59%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "258b6560",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from random import shuffle\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier,ExtraTreesClassifier\n",
    "from sklearn import svm,metrics,preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "#from scipy.misc import imread, imresize\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9598949a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (conv_stem): Conv2dSame(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "  (bn1): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act1): SiLU(inplace=True)\n",
       "  (blocks): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): DepthwiseSeparableConv(\n",
       "        (conv_dw): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "        (bn1): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pw): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): Identity()\n",
       "      )\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2dSame(96, 96, kernel_size=(3, 3), stride=(2, 2), groups=96, bias=False)\n",
       "        (bn2): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "        (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2dSame(144, 144, kernel_size=(5, 5), stride=(2, 2), groups=144, bias=False)\n",
       "        (bn2): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "        (bn2): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(40, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2dSame(240, 240, kernel_size=(3, 3), stride=(2, 2), groups=240, bias=False)\n",
       "        (bn2): BatchNorm2d(240, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (bn2): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "        (bn2): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "        (bn2): BatchNorm2d(480, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2dSame(672, 672, kernel_size=(5, 5), stride=(2, 2), groups=672, bias=False)\n",
       "        (bn2): BatchNorm2d(672, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): InvertedResidual(\n",
       "        (conv_pw): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act1): SiLU(inplace=True)\n",
       "        (conv_dw): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "        (bn2): BatchNorm2d(1152, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (act2): SiLU(inplace=True)\n",
       "        (se): SqueezeExcite(\n",
       "          (conv_reduce): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (act1): SiLU(inplace=True)\n",
       "          (conv_expand): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (conv_pwl): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (bn3): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv_head): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (bn2): BatchNorm2d(1280, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (act2): SiLU(inplace=True)\n",
       "  (global_pool): SelectAdaptivePool2d (pool_type=avg, flatten=True)\n",
       "  (classifier): Identity()\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = r'D:\\Users\\amira\\openvino_notebooks\\notebooks\\accuracy_afew\\models\\enet_b0_8\\enet_b0_8.pt'\n",
    "\n",
    "feature_extractor_model = torch.load(PATH)\n",
    "feature_extractor_model.classifier=torch.nn.Identity()\n",
    "feature_extractor_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e47afd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR=r'D:\\Users\\amira\\Documents\\datasets\\emotions\\AudioVideo\\faces'\n",
    "IMG_SIZE = 224\n",
    "\n",
    "emotion_to_index = {'Angry':0, 'Disgust':1, 'Fear':2, 'Happy':3, 'Neutral':4, 'Sad':5, 'Surprise':6}\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55d267aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((IMG_SIZE,IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26719665",
   "metadata": {},
   "source": [
    "Path to directory is organised like DATA_DIR/Val_AFEW/emotion_name/video_name/[images from MTCNN]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ef10c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(data_dir):\n",
    "    filename2features={}\n",
    "    for class_name in os.listdir(data_dir):\n",
    "        if class_name in emotion_to_index:\n",
    "            class_dir = os.path.join(data_dir, class_name)\n",
    "        for video_name in tqdm(os.listdir(class_dir)):\n",
    "            frames_dir=os.path.join(class_dir,video_name)\n",
    "            X_global_features,X_isface=[],[]\n",
    "            imgs=[]\n",
    "            for img_name in os.listdir(frames_dir):\n",
    "                img = Image.open(os.path.join(frames_dir,img_name))\n",
    "                img_tensor = test_transforms(img)\n",
    "                X_isface.append('noface' not in img_name)\n",
    "                    \n",
    "                if img.size:\n",
    "                    imgs.append(img_tensor)\n",
    "                    if len(imgs)>=16:        \n",
    "                        #global_features,feats,scores=feature_extractor_model.predict(inp)\n",
    "                        scores = feature_extractor_model(torch.stack(imgs, dim=0).to(device))\n",
    "                        scores=scores.data.cpu().numpy()\n",
    "                        #print(scores.shape)\n",
    "                \n",
    "                        #print(global_features.shape,feats.shape,scores.shape)\n",
    "                        if len(X_global_features)==0:\n",
    "                            X_global_features=scores\n",
    "                        else:\n",
    "                            X_global_features=np.concatenate((X_global_features,scores),axis=0)\n",
    "                        \n",
    "                        imgs=[]\n",
    "\n",
    "            if len(imgs)>0:   \n",
    "                scores = feature_extractor_model(torch.stack(imgs, dim=0).to(device))\n",
    "                scores=scores.data.cpu().numpy()\n",
    "                #print(scores.shape)\n",
    "\n",
    "                #print(global_features.shape,feats.shape,scores.shape)\n",
    "                if len(X_global_features)==0:\n",
    "                    X_global_features=scores\n",
    "                else:\n",
    "                    X_global_features=np.concatenate((X_global_features,scores),axis=0)\n",
    "\n",
    "            X_isface=np.array(X_isface)\n",
    "            #print(X_global_features.shape,X_feats.shape,X_scores.shape)\n",
    "            filename2features[video_name]=(X_global_features,X_isface)\n",
    "    return filename2features\n",
    "\n",
    "filename2features_val=get_features(os.path.join(DATA_DIR, 'Val_AFEW'))\n",
    "filename2features_train=get_features(os.path.join(DATA_DIR, 'Train_AFEW'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e864ac",
   "metadata": {},
   "source": [
    "Sav and load extracted features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5396a9de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_afew_torch.pickle\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "model_name = 'enet_b0_8'\n",
    "MODEL2EMOTIW_FEATURES=model_name+'_afew_torch.pickle' \n",
    "\n",
    "print(MODEL2EMOTIW_FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b95195c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(MODEL2EMOTIW_FEATURES, 'wb') as handle:\n",
    "    pickle.dump([filename2features_train,filename2features_val], handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "defe23b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "773 383\n"
     ]
    }
   ],
   "source": [
    "with open(MODEL2EMOTIW_FEATURES, 'rb') as handle:\n",
    "    filename2features_train,filename2features_val=pickle.load(handle)\n",
    "print(len(filename2features_train),len(filename2features_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4381568d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b28261c23349dea22c7c72d8f2a3ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/133 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a75d89ae3904976bda279d2aba6a397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc8a786466d84b6a9fb6dd8a0bd6e3cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/81 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47a13e664ff6449fb3c34e2042542d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0dcc8e85fa146dbab292ea956c46c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/144 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b7251273d8d4cf5b0797778b593c95d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/117 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "093c4a5d5fff4ab68821a6a61fb53c65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(773, 5120) (773,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d69af74dbca84c959fef6e1fc622232c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55ed027a11ff4bc981b490d95b63efff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17cf7c4ac50a449eb1cdc374f9af5ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b251f2975655438dbe2fa5082e573d1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6a382cef3954c62a16c9924a92fd647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c024e7933d2451bbd988620da64c792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/61 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32ec388841b2404d9172440bc2bdd46f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/46 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(383, 5120) (383,)\n"
     ]
    }
   ],
   "source": [
    "def create_dataset(filename2features,data_dir):\n",
    "    x = []\n",
    "    y = []\n",
    "    has_faces=[]\n",
    "    ind=0\n",
    "    for class_name in emotion_to_index:\n",
    "        for filename in tqdm(os.listdir(os.path.join(data_dir,class_name))):\n",
    "            fn=os.path.splitext(filename)[0] # goes through files names\n",
    "            if not fn in filename2features:\n",
    "                continue\n",
    "            features=filename2features[fn]\n",
    "            total_features=None\n",
    "            #print(len(features))\n",
    "            if True:\n",
    "                if len(features[0])!=0:\n",
    "                    cur_features=features[0][features[-1]==1]\n",
    "                #print(prev,features.shape)\n",
    "            else:\n",
    "                cur_features=features[0]\n",
    "            if len(cur_features)==0:\n",
    "                has_faces.append(0)\n",
    "                total_features=np.zeros_like(feature)\n",
    "            else:\n",
    "                has_faces.append(1)\n",
    "                #mean_features=features.mean(axis=0)\n",
    "                mean_features = (np.mean(cur_features, axis=0))\n",
    "                std_features = (np.std(cur_features, axis=0))\n",
    "                max_features = (np.max(cur_features, axis=0))\n",
    "                min_features = (np.min(cur_features, axis=0))\n",
    "\n",
    "                # join several features together\n",
    "                feature = np.concatenate((mean_features, std_features, min_features, max_features), axis=None)                    \n",
    "                #feature = np.concatenate((mean_features, std_features, min_features), axis=None)\n",
    "                #feature = np.concatenate((mean_features, min_features, max_features), axis=None)\n",
    "                #feature = np.concatenate((max_features, std_features), axis=None)\n",
    "                #feature=max_features\n",
    "\n",
    "                total_features=feature\n",
    "            \n",
    "            if total_features is not None:\n",
    "                x.append(total_features)\n",
    "                y.append(emotion_to_index[class_name])\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    has_faces=np.array(has_faces)\n",
    "    print(x.shape,y.shape)\n",
    "    return x,y,has_faces\n",
    "\n",
    "x_train, y_train, has_faces_train = create_dataset(filename2features_train, os.path.join(DATA_DIR, 'Train_AFEW'))\n",
    "x_test, y_test, has_faces_test = create_dataset(filename2features_val, os.path.join(DATA_DIR, 'Val_AFEW'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9dff020b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm,metrics,preprocessing\n",
    "\n",
    "x_train_norm=preprocessing.normalize(x_train,norm='l2')\n",
    "x_test_norm=preprocessing.normalize(x_test,norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c00df939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5963060686015831\n",
      "Complete accuracy: 0.5900783289817232\n"
     ]
    }
   ],
   "source": [
    "svc_clf = svm.LinearSVC(C=1.1) #0.5 1.1 0.6\n",
    "#clf = svm.SVC(C=10.0, gamma=1.0, kernel='rbf')\n",
    "#np.random.seed(1)\n",
    "#clf=RandomForestClassifier(n_estimators=1000,max_depth=7, n_jobs=-1)\n",
    "#clf=KNeighborsClassifier(n_neighbors=3,p=2)\n",
    "\n",
    "#import xgboost as xgb\n",
    "#clf = xgb.XGBClassifier(n_estimators=1000,use_label_encoder=False)\n",
    "\n",
    "if True:    \n",
    "    svc_clf.fit(x_train_norm[has_faces_train==1], y_train[has_faces_train==1])\n",
    "    y_pred = svc_clf.predict(x_test_norm)\n",
    "else:\n",
    "    clf.fit(x_train[has_faces_train==1], y_train[has_faces_train==1])\n",
    "    y_pred = clf.predict(x_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test[has_faces_test==1], y_pred[has_faces_test==1]))\n",
    "print(\"Complete accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8fe252b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ('Angry', 'Disgust', 'Fear', 'Happy', 'Neutral', 'Sad', 'Surprise')\n",
    "\n",
    "confusion = pd.crosstab(y_test, y_pred, rownames=['y_true'], colnames=['y_pred'])\n",
    "confusion.columns = classes\n",
    "confusion.index = classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aefe6e86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Confusion matrix'}>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 3600x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(50,8))\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax1.set_title('Confusion matrix')\n",
    "sns.heatmap(confusion, annot=True, cmap='Blues', fmt='g')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9de615",
   "metadata": {},
   "source": [
    "## OpenFace features + classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfa0ec11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from random import shuffle\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.svm import SVC,LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier, BaggingClassifier,ExtraTreesClassifier\n",
    "from sklearn import svm,metrics,preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "#from scipy.misc import imread, imresize\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cace839",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_afew_torch.pickle\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "model_name = 'enet_b0_8'\n",
    "MODEL2EMOTIW_FEATURES=model_name+'_afew_torch.pickle' \n",
    "\n",
    "print(MODEL2EMOTIW_FEATURES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12d9f7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "773 383\n"
     ]
    }
   ],
   "source": [
    "with open(MODEL2EMOTIW_FEATURES, 'rb') as handle:\n",
    "    filename2features_train,filename2features_val=pickle.load(handle)\n",
    "print(len(filename2features_train),len(filename2features_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e853a947",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = r'D:\\Users\\amira\\Documents\\datasets\\emotions\\AudioVideo\\openface'\n",
    "IMG_SIZE = 224\n",
    "\n",
    "emotion_to_index = {'Angry':0, 'Disgust':1, 'Fear':2, 'Happy':3, 'Neutral':4, 'Sad':5, 'Surprise':6}\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5e78266",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a80f2375b3004fcd8998cbf7b6ccc9e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86581d6f3eea48a7af06758384d2a795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9188f4b5b4b24a46af995be647b33d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/162 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a0cb7da2df9426dbe87a4881342814c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4354e3e6c6c4c1a8b37ccb91892796a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/288 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828021196fce4d10a2a53ccdf9253216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "306113243b5b49b790f0ccc20be37358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(773, 1316) (773,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c8623bd8641499ab3cff363c19db142",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "078c8fee525e406ca2705ed5c7233970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdad7951084e4171acd7c26e3a4c8f77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5eac080fa1549f89039fd96bf277933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ada1a82c4a0456d9f4322eef0130eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc12f841a62c4afaad549c4d2e8dfa7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/122 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72572e6e67ef4180a5f375015df5e3ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(383, 1316) (383,)\n"
     ]
    }
   ],
   "source": [
    "def create_openface_dataset(data_dir):\n",
    "    x = []\n",
    "    y = []\n",
    "    for class_name in emotion_to_index:\n",
    "        for filename in tqdm(os.listdir(os.path.join(data_dir,class_name))):\n",
    "            fn=os.path.splitext(filename)[0] # goes through files names without extension\n",
    "            if 'of_details' not in fn:\n",
    "                openface_df = pd.read_csv(os.path.join(data_dir,class_name,filename))\n",
    "                # fill zeroes with mean values where openface failed to detect faces \n",
    "                openface_df.loc[openface_df[' success'] == 0] = openface_df.loc[openface_df[' success'] == 0].replace(0, openface_df.loc[openface_df[' success'] == 1].mean())\n",
    "                # remove some irrelevant columns\n",
    "                openface_df = openface_df.loc[:, ~openface_df.columns.isin(['frame', ' face_id', ' timestamp', ' confidence', ' success'])]\n",
    "\n",
    "                total_features=None\n",
    "                mean_features = (np.mean(openface_df, axis=0))\n",
    "                std_features = (np.std(openface_df, axis=0))\n",
    "                max_features = (np.max(openface_df, axis=0))\n",
    "                min_features = (np.min(openface_df, axis=0))\n",
    "\n",
    "                # join several features together\n",
    "                feature = np.concatenate((mean_features, std_features, min_features, max_features), axis=None)                    \n",
    "                #feature = np.concatenate((mean_features, std_features, min_features), axis=None)\n",
    "                #feature = np.concatenate((mean_features, min_features, max_features), axis=None)\n",
    "                #feature = np.concatenate((max_features, std_features), axis=None)\n",
    "                #feature=max_features\n",
    "\n",
    "                total_features=feature\n",
    "                \n",
    "                if total_features is not None:\n",
    "                    x.append(total_features)\n",
    "                    y.append(emotion_to_index[class_name])\n",
    "\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    \n",
    "    print(x.shape,y.shape)\n",
    "    return x,y\n",
    "\n",
    "x_train, y_train = create_openface_dataset(os.path.join(DATA_DIR, 'Train_AFEW'))\n",
    "x_test, y_test = create_openface_dataset(os.path.join(DATA_DIR, 'Val_AFEW'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2948cd94",
   "metadata": {},
   "source": [
    "There are 24 videos from Train and 11 videos from Test where OpenFace completely failed to detect faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aead7333",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_x_train = np.isnan(x_train)\n",
    "openface_has_faces_train = []\n",
    "\n",
    "for i in range(len(bool_x_train)):\n",
    "    openface_has_faces_train.append((len(np.where(bool_x_train[i]==1)[0]) == 0))\n",
    "\n",
    "\n",
    "bool_x_test = np.isnan(x_test)\n",
    "openface_has_faces_test = []\n",
    "\n",
    "for i in range(len(bool_x_test)):\n",
    "    openface_has_faces_test.append((len(np.where(bool_x_test[i]==1)[0]) == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "efb8d090",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm,metrics,preprocessing\n",
    "\n",
    "x_train_norm_of=preprocessing.normalize(x_train[openface_has_faces_train],norm='l2')\n",
    "x_test_norm_of=preprocessing.normalize(x_test[openface_has_faces_test],norm='l2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e6e6eb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete accuracy: 0.34986945169712796\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb_clf = xgb.XGBClassifier(n_estimators=700,use_label_encoder=False)\n",
    "\n",
    "if True:    \n",
    "    xgb_clf.fit(x_train, y_train)\n",
    "    y_pred = xgb_clf.predict(x_test)\n",
    "else:\n",
    "    clf.fit(x_train[has_faces_train==1], y_train[has_faces_train==1])\n",
    "    y_pred = clf.predict(x_test)\n",
    "print(\"Complete accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229cd068",
   "metadata": {},
   "source": [
    "Accuracy is higher when passing all data and the same with and without normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fefe68",
   "metadata": {},
   "source": [
    "## Enet + OpenFace Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c217c9b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enet_b0_8_afew_torch.pickle\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "model_name = 'enet_b0_8'\n",
    "MODEL2EMOTIW_FEATURES=model_name+'_afew_torch.pickle' \n",
    "\n",
    "print(MODEL2EMOTIW_FEATURES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89c2601e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "773 383\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(MODEL2EMOTIW_FEATURES, 'rb') as handle:\n",
    "    filename2features_train,filename2features_val=pickle.load(handle)\n",
    "print(len(filename2features_train),len(filename2features_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcfe0a82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c93803117624b3b9a8d73a52ab2f35d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/266 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb1971158554e70bcde93575934d840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89ac9c921a1d4f2c914a69bf71ce1944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/162 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d18efbea3c664d739d151efd14a876f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/300 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76c51cccce1c4b50840f1eed42045fe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/288 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5c1de1470b549c887302d13219f3db9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/234 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4558e13335c44a3da22c6245ab50139a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/148 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(773, 5120) (773,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f5d92ba76bf43a2a6c5983147ff641b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7012c5a13b042778511f8c8638742e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a6ce275b8c4ad48a38019dbf8f5be4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b516031ba36e4eff8d1da32b27a8a103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d49946f2ff44fa8aa585427acf46b09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e718c7185454ae1b9acf2fef54313b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/122 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "589d8cc0cbf44e65b1bcad366dd1fa41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/92 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(383, 5120) (383,)\n"
     ]
    }
   ],
   "source": [
    "def create_dataset(filename2features,data_dir):\n",
    "    x = []\n",
    "    y = []\n",
    "    has_faces=[]\n",
    "    ind=0\n",
    "    for class_name in emotion_to_index:\n",
    "        for filename in tqdm(os.listdir(os.path.join(data_dir,class_name))):\n",
    "            fn=os.path.splitext(filename)[0] # goes through files names\n",
    "            if not fn in filename2features:\n",
    "                continue\n",
    "            features=filename2features[fn]\n",
    "            total_features=None\n",
    "            #print(len(features))\n",
    "            if True:\n",
    "                if len(features[0])!=0:\n",
    "                    cur_features=features[0][features[-1]==1]\n",
    "                #print(prev,features.shape)\n",
    "            else:\n",
    "                cur_features=features[0]\n",
    "            if len(cur_features)==0:\n",
    "                has_faces.append(0)\n",
    "                total_features=np.zeros_like(feature)\n",
    "            else:\n",
    "                has_faces.append(1)\n",
    "                #mean_features=features.mean(axis=0)\n",
    "                mean_features = (np.mean(cur_features, axis=0))\n",
    "                std_features = (np.std(cur_features, axis=0))\n",
    "                max_features = (np.max(cur_features, axis=0))\n",
    "                min_features = (np.min(cur_features, axis=0))\n",
    "\n",
    "                # join several features together\n",
    "                feature = np.concatenate((mean_features, std_features, min_features, max_features), axis=None)                    \n",
    "                #feature = np.concatenate((mean_features, std_features, min_features), axis=None)\n",
    "                #feature = np.concatenate((mean_features, min_features, max_features), axis=None)\n",
    "                #feature = np.concatenate((max_features, std_features), axis=None)\n",
    "                #feature=max_features\n",
    "\n",
    "                total_features=feature\n",
    "            \n",
    "            if total_features is not None:\n",
    "                x.append(total_features)\n",
    "                y.append(emotion_to_index[class_name])\n",
    "    x=np.array(x)\n",
    "    y=np.array(y)\n",
    "    has_faces=np.array(has_faces)\n",
    "    print(x.shape,y.shape)\n",
    "    return x,y,has_faces\n",
    "\n",
    "x_train_frames, y_train_frames, has_faces_train = create_dataset(filename2features_train, os.path.join(DATA_DIR, 'Train_AFEW'))\n",
    "x_test_frames, y_test_frames, has_faces_test = create_dataset(filename2features_val, os.path.join(DATA_DIR, 'Val_AFEW'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cff819db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm,metrics,preprocessing\n",
    "\n",
    "x_train_norm=preprocessing.normalize(x_train_frames,norm='l2')\n",
    "x_test_norm=preprocessing.normalize(x_test_frames,norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "48e4b03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_cat = np.concatenate((x_train_norm,x_train),axis=1)\n",
    "x_test_cat = np.concatenate((x_test_norm,x_test),axis=1)\n",
    "\n",
    "valid_train = np.multiply(has_faces_train, openface_has_faces_train)\n",
    "valid_test = np.multiply(has_faces_test, openface_has_faces_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6469276d",
   "metadata": {},
   "source": [
    "All features from Enet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efcc9437",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5514511873350924\n",
      "Complete accuracy: 0.5483028720626631\n"
     ]
    }
   ],
   "source": [
    "#clf = svm.LinearSVC(C=1.1) #0.5 1.1 0.6\n",
    "#clf = svm.SVC(C=10.0, gamma=1.0, kernel='rbf')\n",
    "#np.random.seed(1)\n",
    "#clf=RandomForestClassifier(n_estimators=1000,max_depth=7, n_jobs=-1)\n",
    "#clf=KNeighborsClassifier(n_neighbors=3,p=2)\n",
    "\n",
    "import xgboost as xgb\n",
    "clf = xgb.XGBClassifier(n_estimators=1000,use_label_encoder=False)\n",
    "\n",
    "if True:    \n",
    "    clf.fit(x_train_norm, y_train)\n",
    "    y_pred = clf.predict(x_test_norm)\n",
    "else:\n",
    "    clf.fit(x_train[has_faces_train==1], y_train[has_faces_train==1])\n",
    "    y_pred = clf.predict(x_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test[has_faces_test==1], y_pred[has_faces_test==1]))\n",
    "print(\"Complete accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e343311",
   "metadata": {},
   "source": [
    "Concatenated features from Enet and OpenFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "60280513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete accuracy: 0.5248041775456919\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "xgb_clf = xgb.XGBClassifier(n_estimators=2000,use_label_encoder=False)\n",
    "\n",
    "if True:    \n",
    "    xgb_clf.fit(x_train_cat, y_train)\n",
    "    y_pred = xgb_clf.predict(x_test_cat)\n",
    "else:\n",
    "    clf.fit(x_train[has_faces_train==1], y_train[has_faces_train==1])\n",
    "    y_pred = clf.predict(x_test)\n",
    "print(\"Complete accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6125e66",
   "metadata": {},
   "source": [
    "Concatenated features but only that have faces in Openface and Enet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76acc4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = svm.LinearSVC(C=1.1, max_iter=2000) #0.5 1.1 0.6\n",
    "#clf = svm.SVC(C=10.0, gamma=1.0, kernel='rbf')\n",
    "np.random.seed(1)\n",
    "#rf_clf=RandomForestClassifier(n_estimators=2300,max_depth=12, n_jobs=-1)\n",
    "#clf=KNeighborsClassifier(n_neighbors=3,p=2)\n",
    "\n",
    "import xgboost as xgb\n",
    "xgb_clf = xgb.XGBClassifier(n_estimators=1500,use_label_encoder=False)\n",
    "\n",
    "if True:    \n",
    "    xgb_clf.fit(x_train_cat[valid_train==1], y_train[valid_train==1])\n",
    "    y_pred = xgb_clf.predict(x_test_cat[valid_test==1])\n",
    "else:\n",
    "    clf.fit(x_train[has_faces_train==1], y_train[has_faces_train==1])\n",
    "    y_pred = clf.predict(x_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test[valid_test==1], y_pred))\n",
    "print(\"Complete accuracy:\",metrics.accuracy_score(y_test[valid_test==1], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "770a7744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.543010752688172\n",
      "Complete accuracy: 0.543010752688172\n"
     ]
    }
   ],
   "source": [
    "# clf = svm.LinearSVC(C=1.1, max_iter=2000) #0.5 1.1 0.6\n",
    "#clf = svm.SVC(C=10.0, gamma=1.0, kernel='rbf')\n",
    "np.random.seed(1)\n",
    "rf_clf=RandomForestClassifier(n_estimators=2300,max_depth=12, n_jobs=-1)\n",
    "#clf=KNeighborsClassifier(n_neighbors=3,p=2)\n",
    "\n",
    "#import xgboost as xgb\n",
    "#clf = xgb.XGBClassifier(n_estimators=1500,use_label_encoder=False)\n",
    "\n",
    "if True:    \n",
    "    rf_clf.fit(x_train_cat[valid_train==1], y_train[valid_train==1])\n",
    "    y_pred = rf_clf.predict(x_test_cat[valid_test==1])\n",
    "else:\n",
    "    clf.fit(x_train[has_faces_train==1], y_train[has_faces_train==1])\n",
    "    y_pred = clf.predict(x_test)\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test[valid_test==1], y_pred))\n",
    "print(\"Complete accuracy:\",metrics.accuracy_score(y_test[valid_test==1], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca6c92b",
   "metadata": {},
   "source": [
    "### Ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "3d6d11a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5645161290322581\n",
      "Complete accuracy: 0.5645161290322581\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "vote_clf = VotingClassifier(estimators=[('rf', rf_clf), ('xgb', xgb_clf)], voting='soft')\n",
    "vote_clf.fit(x_train_cat[valid_train==1], y_train[valid_train==1])\n",
    "y_pred = vote_clf.predict(x_test_cat[valid_test==1])\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test[valid_test==1], y_pred))\n",
    "print(\"Complete accuracy:\",metrics.accuracy_score(y_test[valid_test==1], y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f1da7a1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.553763440860215\n",
      "Complete accuracy: 0.553763440860215\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingClassifier\n",
    "\n",
    "st_clf = StackingClassifier(estimators=[('rf', rf_clf), ('xgb', xgb_clf)])\n",
    "st_clf.fit(x_train_cat[valid_train==1], y_train[valid_train==1])\n",
    "y_pred = st_clf.predict(x_test_cat[valid_test==1])\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test[valid_test==1], y_pred))\n",
    "print(\"Complete accuracy:\",metrics.accuracy_score(y_test[valid_test==1], y_pred))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ed3981b15a223883aee74f0ceebf90ae99ff8cc4fd329eb8565e2053aa83b18"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
