{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from openvino.runtime import Core\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm,metrics,preprocessing\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.decomposition import PCA\n",
    "#from sklearn.pipeline import Pipeline\n",
    "#from sklearn.metrics.pairwise import pairwise_distances\n",
    "from torchvision import transforms\n",
    "\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# путь к видео\n",
    "DATA_DIR=r'D:\\Users\\amira\\Documents\\datasets\\emotions\\sample'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Users\\amira\\Documents\\datasets\\emotions\\sample\\video.mp4\n"
     ]
    }
   ],
   "source": [
    "video_path=os.path.normpath(os.path.join(DATA_DIR,'video.mp4'))\n",
    "print(video_path)\n",
    "faces_path=os.path.normpath(os.path.join(DATA_DIR,'faces'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "FRAMES_TO_SKIP = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import facial_analysis.FacialImageProcessing as FacialImageProcessing\n",
    "imgProcessing=FacialImageProcessing(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(faces_path):\n",
    "    os.mkdir(faces_path)\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print('total_frames:',total_frames)\n",
    "\n",
    "frame_count = 0\n",
    "counter=0\n",
    "\n",
    "for frame_count in tqdm(range(0, total_frames-1, FRAMES_TO_SKIP)):\n",
    "    ret, frame_bgr = cap.read()\n",
    "    counter+=FRAMES_TO_SKIP\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, counter)\n",
    "    if not ret:\n",
    "        #cap.release()\n",
    "        #break\n",
    "        continue\n",
    "    frame = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "    bounding_boxes, _ = imgProcessing.detect_faces(frame)\n",
    "    if len(bounding_boxes)!=0:\n",
    "        if len(bounding_boxes)>1:\n",
    "            bounding_boxes=bounding_boxes[:1]\n",
    "\n",
    "        b=[int(bi) for bi in bounding_boxes[0]]\n",
    "        x1,y1,x2,y2=b[0:4]\n",
    "        face_img=frame_bgr[y1:y2,x1:x2,:]        \n",
    "\n",
    "        outfile=os.path.join(faces_path, str(counter)+'.png') \n",
    "\n",
    "        if np.prod(face_img.shape)==0:\n",
    "            print('Empty face ',b,' found for ',filename)\n",
    "            continue\n",
    "        cv2.imwrite(outfile, face_img) \n",
    "        \n",
    "    \n",
    "cap.release()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ConstOutput: names[x.1] shape{1,3,224,224} type: f32>\n",
      "<ConstOutput: names[652] shape{1,1280} type: f32>\n"
     ]
    }
   ],
   "source": [
    "ie = Core()\n",
    "# path to xml file with model converted to OpenVino's IR format. bin file should be in the same directory\n",
    "model = ie.read_model(model=os.path.normpath(r\"models\\enet_b0_FP16\\enet_b0_8_FP16.xml\"))\n",
    "# adding extra output layer\n",
    "model.add_outputs(['652'])\n",
    "feature_extractor = ie.compile_model(model=model, device_name=\"CPU\")\n",
    "input_layer = next(iter(feature_extractor.inputs))\n",
    "output_layer = feature_extractor.outputs[1]\n",
    "print(input_layer)\n",
    "print(output_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize((224,224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])\n",
    "    ]\n",
    ")\n",
    "\n",
    "def torch_transforms(filepath):\n",
    "    face_img = Image.open(filepath)\n",
    "    img_tensor = test_transforms(face_img)\n",
    "    img_arr = img_tensor.numpy()\n",
    "    img_arr = np.expand_dims(img_arr, axis=0)\n",
    "    return img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "emotion_to_index = {'Angry':0, 'Disgust':1, 'Fear':2, 'Happy':3, 'Neutral':4, 'Sad':5, 'Surprise':6}\n",
    "\n",
    "\n",
    "def get_features(data_dir):\n",
    "    filename2features={}\n",
    "\n",
    "    video_scores=[]\n",
    "    X_isface=[]\n",
    "    for img_name in os.listdir(data_dir):\n",
    "        filepath=os.path.join(data_dir,img_name)\n",
    "        input_image = torch_transforms(filepath)\n",
    "        X_isface.append('noface' not in img_name)\n",
    "            \n",
    "        if input_image.size:\n",
    "            scores = feature_extractor(inputs=[input_image])[output_layer]\n",
    "            scores = scores[0].squeeze()\n",
    "            video_scores.append(scores)\n",
    "    filename2features['video_name']=(np.array(video_scores),np.array(X_isface))\n",
    "    return filename2features\n",
    "\n",
    "filename2features=get_features(faces_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5120)\n"
     ]
    }
   ],
   "source": [
    "def create_dataset(filename2features):\n",
    "    x = []\n",
    "    y = []\n",
    "    has_faces=[]\n",
    "    ind=0\n",
    "    fn='video_name'\n",
    "\n",
    "    features=filename2features[fn]\n",
    "    total_features=None\n",
    "    #print(len(features))\n",
    "    if True:\n",
    "        if len(features[0])!=0:\n",
    "            cur_features=features[0][features[-1]==1]\n",
    "        #print(prev,features.shape)\n",
    "    else:\n",
    "        cur_features=features[0]\n",
    "    if len(cur_features)==0:\n",
    "        has_faces.append(0)\n",
    "        total_features=np.zeros_like(feature)\n",
    "    else:\n",
    "        has_faces.append(1)\n",
    "        mean_features = (np.mean(cur_features, axis=0))\n",
    "        std_features = (np.std(cur_features, axis=0))\n",
    "        max_features = (np.max(cur_features, axis=0))\n",
    "        min_features = (np.min(cur_features, axis=0))\n",
    "\n",
    "        # join several features together\n",
    "        feature = np.concatenate((mean_features, std_features, min_features, max_features), axis=None)                    \n",
    "\n",
    "        total_features=feature\n",
    "    \n",
    "    if total_features is not None:\n",
    "        x.append(total_features)\n",
    "    x=np.array(x)\n",
    "    has_faces=np.array(has_faces)\n",
    "    print(x.shape)\n",
    "    return x,has_faces\n",
    "\n",
    "x_test, has_faces_test = create_dataset(filename2features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_test_norm=preprocessing.normalize(x_test,norm='l2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    " # load the model from disk\n",
    "filename = 'linear_svc.sav'\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "y_pred = loaded_model.predict(x_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ed3981b15a223883aee74f0ceebf90ae99ff8cc4fd329eb8565e2053aa83b18"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}