{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AFEW Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR=r'D:\\Users\\amira\\Documents\\datasets\\emotions\\AudioVideo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_dir(dirname):\n",
    "    resdir=os.path.join(DATA_DIR,'frames', 'Val_AFEW')\n",
    "    d = os.path.normpath(os.path.join(DATA_DIR, 'Val_AFEW', dirname))\n",
    "    for filename in tqdm(os.listdir(d)):\n",
    "        if os.path.isdir(os.path.normpath(os.path.join(d,filename))):\n",
    "            videofile=None\n",
    "            for fn in os.listdir(os.path.normpath(os.path.join(d,filename))):\n",
    "                videofile=fn\n",
    "            if videofile is None:\n",
    "                continue\n",
    "            filename=os.path.normpath(os.path.join(filename,videofile))\n",
    "        fn, ext = os.path.splitext(os.path.basename(filename))\n",
    "        outdir=os.path.normpath(os.path.join(resdir,dirname,fn))\n",
    "        if not os.path.exists(outdir):\n",
    "            os.makedirs(outdir)\n",
    "        command = \"ffmpeg -r 1 -i \"+os.path.join(d,filename) + \" -r 1 \"+outdir+\"/%05d.png\"\n",
    "        command = os.path.normpath(command)\n",
    "        print(command)\n",
    "        os.system(command=command)\n",
    "\n",
    "\n",
    "for emotion_name in os.listdir(os.path.normpath(os.path.join(DATA_DIR, 'Val_AFEW'))):\n",
    "    process_dir(emotion_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get one face from frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'D:\\\\Users\\\\amira\\\\emotion-recognition\\\\code\\\\mtcnn.pb': ''}\n"
     ]
    }
   ],
   "source": [
    "from facial_analysis import FacialImageProcessing\n",
    "imgProcessing=FacialImageProcessing(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR='D:/Users/amira/Documents/datasets/emotions/AudioVideo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (224,224)\n",
    "def save_faces(source_path,save_path):\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    for folder in tqdm(os.listdir(source_path)):\n",
    "        #print(folder)\n",
    "        if not os.path.exists(os.path.join(save_path, folder)):\n",
    "            os.mkdir(os.path.join(save_path, folder))\n",
    "\n",
    "            for image in os.listdir(os.path.join(source_path, folder)):\n",
    "                filename = os.path.join(source_path, folder, image)\n",
    "                frame_bgr = cv2.imread(filename)\n",
    "                frame = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "                bounding_boxes, _ = imgProcessing.detect_faces(frame)\n",
    "\n",
    "                if len(bounding_boxes)==0:\n",
    "                    print('No faces found for ',filename)\n",
    "                    face_img = frame_bgr\n",
    "                    faceFound='noface'\n",
    "                else:\n",
    "                    if len(bounding_boxes)>1:\n",
    "                        print('Too many faces (',len(bounding_boxes),') found for ',filename)\n",
    "                        bounding_boxes=bounding_boxes[:1]\n",
    "\n",
    "                    b=[int(bi) for bi in bounding_boxes[0]]\n",
    "                    x1,y1,x2,y2=b[0:4]\n",
    "                    face_img=frame_bgr[y1:y2,x1:x2,:]\n",
    "\n",
    "                    if np.prod(face_img.shape)==0:\n",
    "                        print('Empty face ',b,' found for ',filename)\n",
    "                        continue\n",
    "                \n",
    "                    faceFound=''\n",
    "\n",
    "                root,ext=os.path.splitext(image)\n",
    "                cv2.imwrite(os.path.join(save_path, folder, root+faceFound+ext), face_img) \n",
    "        else:\n",
    "            print(folder)\n",
    "\n",
    "for emotion_name in os.listdir(os.path.normpath(os.path.join(DATA_DIR, 'frames/Train_AFEW'))):        \n",
    "    save_faces(os.path.join(DATA_DIR,'frames/Train_AFEW', emotion_name), os.path.join(DATA_DIR,'faces/Train_AFEW', emotion_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get multiple faces from frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'D:\\\\Users\\\\amira\\\\emotion-recognition\\\\code\\\\mtcnn.pb': ''}\n"
     ]
    }
   ],
   "source": [
    "from facial_analysis import FacialImageProcessing\n",
    "imgProcessing=FacialImageProcessing(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR='D:/Users/amira/Documents/datasets/emotions/AudioVideo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_SIZE = (224,224)\n",
    "def save_faces(source_path,save_path):\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    for folder in tqdm(os.listdir(source_path)):\n",
    "        #print(folder)\n",
    "        if not os.path.exists(os.path.join(save_path, folder)):\n",
    "            os.mkdir(os.path.join(save_path, folder))\n",
    "\n",
    "            for image in os.listdir(os.path.join(source_path, folder)):\n",
    "                filename = os.path.join(source_path, folder, image)\n",
    "                frame_bgr = cv2.imread(filename)\n",
    "                frame = cv2.cvtColor(frame_bgr, cv2.COLOR_BGR2RGB)\n",
    "                bounding_boxes, _ = imgProcessing.detect_faces(frame)\n",
    "\n",
    "                if len(bounding_boxes)==0:\n",
    "                    print('No faces found for ',filename)\n",
    "                    face_img = frame_bgr\n",
    "                    faceFound='noface'\n",
    "                else:\n",
    "                    print('(',len(bounding_boxes),') faces found for ',filename)\n",
    "                    for i in range(len(bounding_boxes)):\n",
    "                        bounding_box=bounding_boxes[i]\n",
    "\n",
    "                        b=[int(bi) for bi in bounding_box]\n",
    "                        x1,y1,x2,y2=b[0:4]\n",
    "                        face_img=frame_bgr[y1:y2,x1:x2,:]\n",
    "\n",
    "                        if np.prod(face_img.shape)==0:\n",
    "                            print('Empty face ',b,' found for ',filename)\n",
    "                            continue\n",
    "                    \n",
    "                        faceFound='_'+str(i)\n",
    "\n",
    "                #face_img=cv2.resize(face_img,INPUT_SIZE)\n",
    "                root,ext=os.path.splitext(image)\n",
    "                cv2.imwrite(os.path.join(save_path, folder, root+faceFound+ext), face_img) \n",
    "        else:\n",
    "            print(folder)\n",
    "\n",
    "for emotion_name in os.listdir(os.path.normpath(os.path.join(DATA_DIR, 'frames/Train_AFEW'))):        \n",
    "    save_faces(os.path.join(DATA_DIR,'frames/Train_AFEW', emotion_name), os.path.join(DATA_DIR,'faces/Train_AFEW', emotion_name))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d5b0939b96e20240b6688bffb0ff6dfbaab1e456544936bbdb82861744a570ee"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
